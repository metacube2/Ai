# Quick Start Guide

Schnellstart-Anleitung f√ºr die Mail Fine-Tuning App.

## 1. Installation (5 Minuten)

```bash
# 1. Virtual Environment erstellen
python3 -m venv venv
source venv/bin/activate

# 2. Dependencies installieren
pip install -r requirements.txt

# 3. Modell herunterladen (ca. 4GB, dauert je nach Internetverbindung)
huggingface-cli download mlx-community/Mistral-7B-Instruct-v0.3-4bit \
    --local-dir models/Mistral-7B-Instruct-v0.3-4bit
```

## 2. Server starten

```bash
./start.sh
```

Oder manuell:

```bash
source venv/bin/activate
cd backend
python main.py
```

App √∂ffnen: **http://localhost:8000**

## 3. Erste Schritte (10 Minuten)

### Schritt 1: Test-Mails erstellen

Erstelle eine Datei `test.txt` mit einer Beispiel-Mail:

```
Subject: Projekt Update
From: max@example.com
To: team@example.com

Hallo Team,

das neue Feature ist fertig und bereit f√ºr Testing.
Ich habe die API-Integration abgeschlossen und alle Tests laufen durch.

Bitte reviewt den Code bis Freitag.

Gr√º√üe
Max
```

### Schritt 2: Mails importieren

1. √ñffne http://localhost:8000
2. Ziehe `test.txt` in den Upload-Bereich
3. Mail erscheint in der Liste

### Schritt 3: Erste Mail labeln

1. Klicke auf "Labeling" in der Sidebar
2. W√§hle **Aufgabentyp**: "Zusammenfassen"
3. Gib **erwarteten Output** ein:
   ```
   Max hat das neue Feature fertiggestellt und alle Tests sind erfolgreich.
   Das Team soll den Code bis Freitag reviewen.
   ```
4. Klicke "Speichern" (oder dr√ºcke `S`)

### Schritt 4: Mehr Mails labeln

- Erstelle mindestens **20-50 Beispiel-Mails**
- Nutze verschiedene Typen:
  - Zusammenfassen
  - Antwort schreiben
  - Action Items extrahieren
- Nutze Shortcuts: `N` (N√§chste), `S` (Speichern)

### Schritt 5: Statistiken pr√ºfen

1. Gehe zu "Export & Stats"
2. Pr√ºfe:
   - Mind. 50 gelabelte Mails? ‚úÖ
   - Gute Verteilung der Task-Types? ‚úÖ

### Schritt 6: Training starten

1. Gehe zu "Training"
2. W√§hle dein Modell aus
3. Nutze Standard-Einstellungen:
   - Learning Rate: 1e-5
   - Epochs: 3
   - Batch Size: 4
   - LoRA Rank: 8
4. Klicke "Training starten"
5. Beobachte Live-Updates

‚è±Ô∏è **Training dauert**: Ca. 5-10 Minuten bei 50 Beispielen

### Schritt 7: Modell testen

1. Gehe zu "Evaluation"
2. Klicke "Test-Beispiel laden"
3. Klicke "Vergleich starten"
4. Vergleiche Base- vs. Fine-tuned-Ausgabe

## Tipps

### Gute Trainingsdaten

‚úÖ **DO**:
- Mindestens 50 Beispiele
- Konsistenter Output-Stil
- Diverse Mail-Typen
- Klare, eindeutige Labels

‚ùå **DON'T**:
- Zu wenige Beispiele (<20)
- Widerspr√ºchliche Labels
- Nur sehr √§hnliche Mails
- Zu lange Outputs (>500 W√∂rter)

### Training-Parameter

F√ºr **erste Versuche**:
- Learning Rate: **1e-5**
- Epochs: **3**
- Batch Size: **4**
- LoRA Rank: **8**

Bei **Overfitting** (Val Loss steigt):
- Learning Rate: **5e-6** (niedriger)
- Epochs: **2** (weniger)

Bei **Underfitting** (beide Losses hoch):
- Epochs: **5** (mehr)
- LoRA Rank: **16** (h√∂her)
- Mehr Daten sammeln!

### Keyboard Shortcuts

Im Labeling-Interface:
- `N` - N√§chste Mail
- `S` - Speichern
- `K` - Skip (√úberspringen)

## Troubleshooting

### Server startet nicht

```bash
# Pr√ºfe Python-Version (mind. 3.10)
python3 --version

# Pr√ºfe ob Port 8000 frei ist
lsof -i :8000

# Nutze anderen Port
uvicorn main:app --port 8001
```

### Modell nicht gefunden

```bash
# Pr√ºfe ob Modell existiert
ls -la models/

# Download nochmal versuchen
huggingface-cli download mlx-community/Mistral-7B-Instruct-v0.3-4bit \
    --local-dir models/Mistral-7B-Instruct-v0.3-4bit
```

### Out of Memory

Reduziere Batch Size:
1. Gehe zu "Training"
2. Setze Batch Size auf **2** oder **1**

### Training sehr langsam

- Nutze 4-bit quantisierte Modelle
- Reduziere Batch Size
- Schlie√üe andere Programme

## N√§chste Schritte

Nach erfolgreichem ersten Training:

1. **Mehr Daten sammeln**: 100+ Beispiele f√ºr bessere Ergebnisse
2. **Parameter tunen**: Experimentiere mit Learning Rate und Epochs
3. **Verschiedene Tasks**: Probiere alle Task-Types aus
4. **Evaluation**: Teste ausgiebig mit neuen Mails

## Ressourcen

- Vollst√§ndige Doku: [README.md](README.md)
- MLX Doku: https://ml-explore.github.io/mlx/
- MLX-LM: https://github.com/ml-explore/mlx-examples

---

**Viel Erfolg! üöÄ**

Bei Fragen schaue ins vollst√§ndige README oder die API-Dokumentation.
